---
title: "HW1"
output: html_document
date: "2023-04-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1

```{r}
library(qeML)
data(pef)
head(pef)
```

Get accuracy of predicting different variables:

```{r}
# Predict wage from all variables; MAE is > $25000
qeLin(pef,'wageinc')$testAcc

# Predict gender from alll variables; Incorrect 24% of the time
qeLogit(pef,'sex')$testAcc

# Predict occupation (6 jobs); Incorrect 64% of the time
qeLogit(pef,'occ')$testAcc
```

## Description:

Format: `takeALookAround(data,yName,sName,maxFeatureSetSize)`

`yName` and `sName` are the names of columns in the data frame `data`

The tool will investigate the impact of using various subsets of the feature set on

-   **(a)** prediction accuracy for Y of this feature set

-   **(b)** prediction accuracy for Y of this feature set plus S (how much are we giving up by NOT using S?)

-   **(c)** prediction accuracy for S of this feature set (the better the accuracy, the less fairness value there is in omitting S from prediction model)

The return value will be a data frame with 4 columns.

1.  A character string consisting of the names of the given feature set.
2.  The prediction accuracy for (a)
3.  The prediction accuracy for (b)
4.  The prediction accuracy for (c)

There will be one row in the d.f. for each feature set. All possible feature sets of size up to **maxFeatureSetSize** will be investigated.

### Case Study with 2 Features:

```{r}
data <- pef
yName <- "wageinc"
sName <- "sex"
maxFeatureSetSize <- 1000

# Select columns excluding yName and sName
featureSet <- colnames(data[,!names(data) %in% c(yName, sName)])
results <- data.frame(matrix(nrow=0, ncol=4))
colnames(results) <- c("features","Y","YS","Accuracy")

i <- 1
j <- 2

feature1 <- featureSet[i] # age
feature2 <- featureSet[j] # educ

data_a <- data[,c(feature1, feature2, yName)]
data_b <- data[,c(feature1, feature2, yName, sName)]
data_c <- data[,c(feature1, feature2, sName)]

if (is.numeric(data[1,yName])) {
  acc_a <- qeLin(data_a,yName)$testAcc
  acc_b <- qeLin(data_b,yName)$testAcc
} else if (is.factor(data[1,yName])) {
  acc_a <- qeLogit(data_b,yName)$testAcc
  acc_b <- qeLogit(data_b,yName)$testAcc
} else {
  acc_a <- NA
  acc_b <- NA
}

if (is.numeric(data[1,sName])) {
  acc_c <- qeLin(data_c,sName)$testAcc
} else if (is.factor(data[1,sName])) {
  acc_c <- qeLogit(data_c,sName)$testAcc
} else {
  acc_c <- NA
}

result <-c(paste(feature1,feature2,sep=","), acc_a, acc_b, acc_c)
results <- rbind.data.frame(results, result)
```

## Implementation:

```{r}
takeALookAround <- function(data, yName, sName, maxFeatureSetSize) {
  
  # Select columns excluding yName and sName
  featureSet <- colnames(data[,!names(data) %in% c(yName, sName)])
  results <- data.frame(matrix(nrow=0, ncol=4))
  
  count <- 0
  for (i in 1:length(featureSet)) {
    for (j in i:length(featureSet)) {
      if (i != j) {
        feature1 <- featureSet[i] # age
        feature2 <- featureSet[j] # educ
        
        data_a <- data[,c(feature1, feature2, yName)]
        data_b <- data[,c(feature1, feature2, yName, sName)]
        data_c <- data[,c(feature1, feature2, sName)]
        
        if (is.numeric(data[1,yName])) {
          acc_a <- qeLin(data_a,yName)$testAcc
          acc_b <- qeLin(data_b,yName)$testAcc
        } else if (is.factor(data[1,yName])) {
          acc_a <- qeLogit(data_b,yName)$testAcc
          acc_b <- qeLogit(data_b,yName)$testAcc
        } else {
          acc_a <- NA
          acc_b <- NA
        }
        
        if (is.numeric(data[1,sName])) {
          acc_c <- qeLin(data_c,sName)$testAcc
        } else if (is.factor(data[1,sName])) {
          acc_c <- qeLogit(data_c,sName)$testAcc
        } else {
          acc_c <- NA
        }
        
        result <-c(paste(feature1,feature2,sep=","), acc_a, acc_b, acc_c)
        results <- rbind.data.frame(results, result)
        count <- count+1
        if (count == maxFeatureSetSize) break
      }
    }
    if (count == maxFeatureSetSize) break
  }
  print(count)
  colnames(results) <- c("features","Y_acc","YS_acc","S_acc")
  return(results)
}
```

## Test Function on Example

```{r}
#data <- pef
#yName <- "wageinc"
#sName <- "sex"
#maxFeatureSetSize <- 1000

wageinc_sex <- takeALookAround(data=pef, 
                               yName="wageinc", 
                               sName="sex", 
                               maxFeatureSetSize=100)
View(wageinc_sex)
wageinc_educ <- takeALookAround(data=pef, 
                               yName="wageinc", 
                               sName="educ", 
                               maxFeatureSetSize=100)
View(wageinc_educ)
```

# Problem 2

## Description:

### Simpson's Paradox

relation(X,Y) is + but relation(X,Y\|Z) is -, or vice versa

Usually, e.g. in the **UCBAdmissions** data, the variables X, Y and Z are all categorical. Your code here will explore whether SP seems to hold for numeric X and Y (and maybe Z) for some given dataset

### Variables

-   **data** is an R data frame or equivalent

-   **xName** is the name of the X column

-   **yName** is the name of the Y column

-   **zName** is the name of the Z column

-   **numZvals** is the number of intervals to break Z into in the case where Z is a continuous variable

X and Y should either be continuous numeric variables or dichotomous R factors.

```{r}
library(qeML)
library(Kendall)
data(pef)
head(pef)
```

We will define "relation" as one of two types of correlation:

-   If both X and Y are continuous, use the classical Pearson correlation, available in R as **cor()**.

-   If at least one of X and Y is dichotomous, use *Kendall's tau* correlation, code available in the **Kendall** package. You should be able to use **install.packages()** to get this code.

```{r}
cor(pef[,"age"],pef[,"wageinc"])
```

## Implementation

```{r}
numericSimpson <- function(data,xName,yName,zName,numZvals=NULL) {
  # Ensure x/y columns are numeric
  data[,xName] <- as.numeric(data[,xName])
  data[,yName] <- as.numeric(data[,yName])
  # Check if z is categorical
  isFactor <- is.factor(data[,zName])
  
  if (is.null(numZvals)) {
    numZvals <- 4
  }
  
  # If z is categorical, partition by categories
  # If z is numeric, partition by numZvals
  if (isFactor) {
    partition <- split(data,data[,zName])
  } else {
    zMin <- min(data[,zName])
    zMax <- max(data[,zName])+0.0001
    rng <- (zMax - zMin) / numZvals
    
    data$zCategory <- data[,zName] %/% rng
    
    # Add range for plot
    for (i in 1:length(data$zCategory)) {
      zCategory <- data$zCategory[i]
      binMin <- zMin + (zCategory*rng)
      binMax <- zMin + ((zCategory+1)*rng)
      range <- paste("[",paste(binMin, binMax, sep=","), ")", sep="")
      data$zRange[i] <- range
    }
    # Partition by category
    partition <- split(data,data$zCategory)
  }
  
  # Create DF to store corr values
  corrDF <- data.frame(matrix(nrow=0, ncol=2))
  colnames(corrDF) <- c("category","corr")
  
  # If both x and y are continuous, use cor()
  # If at least one is dichotomous, use kendall's tau
  if ((length(unique(data[,xName])) > 2) || (length(unique(data[,yName])) > 2)) {
    usePearson <- TRUE
  } else {
    usePearson <- FALSE
  }
  
  # Collect correlation values
  if (usePearson) { # find pearson correlation
    for (i in 1:length(partition)) {
      df <- partition[[i]]
      if (isFactor) {
        category <- df[,zName][1]
      } else {
        category <- df$zRange[1]
      }
      corr <- cor(df[,xName], df[,yName])
      newDF <- data.frame(matrix(nrow=1,ncol=2))
      colnames(newDF) <- c("category","corr")
      newDF$category <- category
      newDF$corr <- corr
      corrDF <- rbind.data.frame(corrDF,newDF)
    }
    unconditionalCorr <- cor(data[,xName],data[,yName])
  } else { # find kendall's tau correlation
    for (i in 1:length(partition)) {
      df <- partition[[i]]
      if (isFactor) {
        category <- df[,zName][1]
      } else {
        category <- df$zRange[1]
      }
      corr <- Kendall(df[,xName], df[,yName])$tau[1]
      newDF <- data.frame(matrix(nrow=1,ncol=2))
      colnames(newDF) <- c("category","corr")
      newDF$category <- category
      newDF$corr <- corr
      corrDF <- rbind.data.frame(corrDF,newDF)
    }
    unconditionalCorr <- Kendall(data[,xName],data[,yName])$tau[1]
  }
  
  corrDF$corr <- as.numeric(corrDF$corr)
  
  # Plot correlation values in barplot
  names <- unique(corrDF$category)
  title <- paste("X = ",xName,", Y = ",yName,", Z = ",zName,sep="")
  xlab <- "Categories of Z"
  ylab <- paste("Z-Stratified Correlation between X and Y")
  sub <- paste("(Unconditional Correlation = ",unconditionalCorr,")", sep="")
  barplot(corrDF$corr, xlab=xlab, ylab=ylab, ylim=c(-1,1), main=title, sub=sub, col.sub="blue", names.arg=names, col=palette())
  abline(h=unconditionalCorr,col="blue")
  abline(h=0,col="black")
}
```

## Test Samples

```{r}
data <- pef
xName <- "age" # continuous numeric
yName <- "wkswrkd" # continuous numeric
zName <- "wageinc" # numeric
numZvals <- 5
numericSimpson(data,xName,yName,zName,numZvals)
```

```{r}
data <- pef
xName <- "age" # continuous numeric
yName <- "sex" # dichotomous factor
zName <- "wageinc" # numeric
numericSimpson(data,xName,yName,zName,2)
```

```{r}
data <- pef
xName <- "age" # continuous numeric
yName <- "wageinc" # continuous numeric
zName <- "sex" # categorical
numericSimpson(data,xName,yName,zName,numZvals=NULL)
```

```{r}
numericSimpson(pef,'age','wageinc','wkswrkd',4)
```

```{r}
numericSimpson(pef,'sex','wageinc','wkswrkd',5)
```

```{r}
numericSimpson(pef,'age','wageinc','occ',4)
```

# Extra Credit B

```{r}
superFactor <- function(f1,f2) {
  f3 <- as.factor(paste(f1,f2,sep="_"))
  return (f3)
}
```

```{r}
unique(superFactor(pef$sex, pef$occ))
```

```{r}
unique(superFactor(pef$sex, pef$educ))
```

# Extra Credit A

```{r}
#install.packages(c("devtools"))
#devtools::install_github("ldurazo/kaggler")
library(readr)
library(kaggler)
kgl_auth(creds_file = 'kaggle.json')
response <- kgl_datasets_download_all(owner_dataset = "wduckett/californiaddsexpenditures")

download.file(response[["url"]], "temp.zip", mode="wb")
unzip_result <- unzip("temp.zip", overwrite = TRUE)
dds <- read_csv("californiaDDSDataV2.csv")
dds <- data.frame(dds)
```

## Ethnicity-Expenditure Correlation Reduces when Age-Stratified

```{r}
dds$Ethnicity <- as.factor(dds$Ethnicity)
dds$GenderBin <- as.numeric(dds$Gender=="Female")
dds$Age.Cohort <- as.factor(dds$Age.Cohort)

#numericSimpson(dds, "Expenditures", "GenderBin","Ethnicity")

data <- dds
xName <- "Expenditures" # continuous numeric
yName <- "Ethnicity" # continuous numeric
zName <- "Age.Cohort" # categorical
numericSimpson(data,xName,yName,zName,numZvals=NULL)
```
